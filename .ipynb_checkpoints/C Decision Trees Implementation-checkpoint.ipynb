{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CPSC 322]() Data Science Algorithms\n",
    "[Gonzaga University](https://www.gonzaga.edu/) |\n",
    "[Sophina Luitel](https://www.gonzaga.edu/school-of-engineering-applied-science/faculty/detail/sophina-luitel-phd-0dba6a9d)\n",
    "\n",
    "---\n",
    "\n",
    "# Decision Trees Implementation\n",
    "What are our learning objectives for this lesson?\n",
    "* Discuss how decision trees can be represented in Python\n",
    "* Go over some hints for getting started on the implementation\n",
    "\n",
    "Content used in this lesson is based upon information in the following sources:\n",
    "* Dr. Gina Sprint's Data Science Algorithms notes\n",
    "* [Data Science from Scratch](https://jcer.in/jcer-docs/E-Learning/Digital%20Library%20/E-Books/Data%20Science%20from%20Scratch%20by%20Joel%20Grus.pdf) by Joel Grus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm-up Task(s) 10/07\n",
    "1. Create a new folder called DecisionTreeFun. Create a DecisionTreeFun/main.py and copy and paste the contents of https://github.com/DataScienceAlgorithms/M5_DecisionTrees/blob/main/DecisionTreeFun/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today \n",
    "* Announcements\n",
    "    * LA11 consists of some questions from the Entropy lab and will be available later today.\n",
    "    \n",
    "* Today\n",
    "    * Finish Entropy Lab\n",
    "    * Recursion examples\n",
    "    * Decision trees implementation in DecisionTreeFun\n",
    "    * IQ5 last ~15 mins of class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing Trees in Python\n",
    "* Can use Python classes\n",
    "* Can use nested data structures (like nested lists or nested dictionaries)\n",
    "\n",
    "Interview example using nested lists (keeping track of the class proportions for each leaf node):\n",
    "        \n",
    "<img src=\"https://raw.githubusercontent.com/DataScienceAlgorithms/M5_DecisionTrees/main/figures/job_candidate_tree.png\" width=\"500\"/>\n",
    "\n",
    "```python\n",
    "[\"Attribute\", \"level\", \n",
    "    [\"Value\", \"Senior\", \n",
    "        [\"Attribute\", \"tweets\", \n",
    "            [\"Value\", \"yes\", \n",
    "                [\"Leaf\", \"True\", 2, 5]\n",
    "            ],\n",
    "            [\"Value\", \"no\", \n",
    "                [\"Leaf\", \"False\", 3, 5]\n",
    "            ]\n",
    "        ]\n",
    "    ],\n",
    "    [\"Value\", \"Mid\", \n",
    "        [\"Leaf\", \"True\", 4, 14]\n",
    "    ],\n",
    "    [\"Value\", \"Junior\", \n",
    "        [\"Attribute\", \"phd\", \n",
    "            [\"Value\", \"yes\", \n",
    "                [\"Leaf\", \"False\", 2, 5]\n",
    "            ],\n",
    "            [\"Value\", \"no\", \n",
    "                [\"Leaf\", \"True\", 3, 5]\n",
    "            ]\n",
    "        ]\n",
    "    ]\n",
    "]\n",
    "```\n",
    "* There are other ways too, these are just a few examples\n",
    "\n",
    "## Main Algorithm\n",
    "`tdidt(instances, att_indexes, att_domains, class_index)`\n",
    "* `instances` is the current partition\n",
    "* `att_indexes` are the indexes of attributes used for classification\n",
    "* `att_domains` the possible values for each attribute (by index)\n",
    "* `class_index` the attribute used as the class label\n",
    "* returns the decision tree\n",
    "    \n",
    "## Helper functions:\n",
    "* `select_attribute(instances, att_indexes, class_index)`\n",
    "    * Returns attribute index to partition on\n",
    "    * Helpful for first step of TDIDT\n",
    "* `partition_instances(instances, att_index, att_domains)`\n",
    "    * Partition list: {att val1:part1, att val2:part2}\n",
    "    * Helpful for second step of TDIDT\n",
    "* `check_all_same_class(instances, class_index)`\n",
    "    * True if all instances have same label\n",
    "    * Helpful for base case #1 (all class labels are the same... make a leaf node)\n",
    "* `compute_partition_stats(instances, class_index)`\n",
    "    * Return a list of stats: `[[label1, occ1, tot1], [label2, occ2, tot2], ...]`\n",
    "    * Helpful for base case #2 (no more attributes to partition, need to handle clashes)\n",
    "\n",
    "## Classification\n",
    "* `classify_tdidt(decision_tree, instance)`\n",
    "    * Takes a decision tree (produced by `tdidt()`) and an instance to classify\n",
    "    * Uses the tree to predict the class label for the instance\n",
    "    * Returns the predicted label for the instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
